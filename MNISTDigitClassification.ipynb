{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKfeZdX76rI+NaFtlicNXI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryaJeet1364/PyTorch_Projects/blob/main/MNISTDigitClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST Digit Classification\n"
      ],
      "metadata": {
        "id": "sFfX5niOqRXx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B89Vx53-qDv_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic normalization for MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)) # MNIST is grayscale, so just one channel\n",
        "])"
      ],
      "metadata": {
        "id": "WRUnoOLyrA8t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading MNIST train and test datasets\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n"
      ],
      "metadata": {
        "id": "4QiE_g1zrHEw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "S6dJmX8erK0U"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple 3-layer MLP\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(784, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "83w-TZ_KrQdI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MLP().to(device)"
      ],
      "metadata": {
        "id": "nEEv9T1UraRo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss() # Using CrossEntropyLoss because it works well with classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "DqzlUxS2rg7L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)"
      ],
      "metadata": {
        "id": "Cs8nDVm_rl_Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Loop\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "cOBrFE7arqfe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_loader)\n",
        "    train_acc = evaluate(model, train_loader)\n",
        "    test_acc = evaluate(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}:\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"  Train Acc : {train_acc * 100:.2f}%\")\n",
        "    print(f\"  Test Acc  : {test_acc * 100:.2f}%\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNucy9D-rv3H",
        "outputId": "bc7f48a2-c17d-4ccf-90bf-bcee6b1f2bfd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "  Train Loss: 0.4063\n",
            "  Train Acc : 93.22%\n",
            "  Test Acc  : 93.02%\n",
            "\n",
            "Epoch 2:\n",
            "  Train Loss: 0.1919\n",
            "  Train Acc : 95.73%\n",
            "  Test Acc  : 95.50%\n",
            "\n",
            "Epoch 3:\n",
            "  Train Loss: 0.1407\n",
            "  Train Acc : 96.26%\n",
            "  Test Acc  : 95.78%\n",
            "\n",
            "Epoch 4:\n",
            "  Train Loss: 0.1142\n",
            "  Train Acc : 97.15%\n",
            "  Test Acc  : 96.46%\n",
            "\n",
            "Epoch 5:\n",
            "  Train Loss: 0.0979\n",
            "  Train Acc : 97.31%\n",
            "  Test Acc  : 96.66%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def predict_random_sample(model, dataset):\n",
        "    model.eval()\n",
        "    index = random.randint(0, len(dataset) - 1)\n",
        "    image, label = dataset[index]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        img_tensor = image.unsqueeze(0).to(device)\n",
        "        output = model(img_tensor)\n",
        "        _, pred = torch.max(output, 1)\n",
        "\n",
        "    plt.imshow(image.squeeze(), cmap='gray')\n",
        "    plt.title(f\"Actual: {label}, Predicted: {pred.item()}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "l54WiXq9r4D_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_random_sample(model, test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "yMAG0jDdtbKn",
        "outputId": "9e9e51f8-ee5f-4b3b-fbec-ed52373f0ddd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFblJREFUeJzt3XuwVWX5wPFnc7iK/ATxAAlykVARjVTUChA1hxhRx1ukWYi3xFtpiJmOgDpAXtOcFBk0TVEcFa1scqYQ1BFLzMG8oaCAGkaoMV4yEHh/fzg+Ix6Fsw9X8fOZ4Q/2Wc9a79mb9vesfZarSimlBABERKNNvQAANh+iAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiwAZVqVRizJgxm3oZm5X9998/9t9///z7ggULolKpxC233LLJ1vRpn14jXx6i8AVy/fXXR6VSiX333bfB+1i0aFGMGTMmZs+evf4WtgH9/e9/j0GDBsX//d//RatWrWLgwIHrtPYZM2ZEpVLJP02aNIkdd9wxhg4dGq+88sr6W/hGMHPmzBgzZkwsXbp0Uy+ljsWLF8cJJ5wQ7dq1ixYtWsSee+4Zd99996ZeFvUgCl8gkydPjq5du8YTTzwR8+bNa9A+Fi1aFBdffPEXIgpPPfVU9OvXL1555ZUYPXp0jBo1KubOnRsDBgyIF198cZ32/eMf/zhuu+22mDhxYgwePDjuuuuu2HvvvWPRokXrafX116VLl/jggw/ihz/8YVVzM2fOjIsvvnizi8I777wT/fr1i3vvvTdOPfXUuPLKK6NVq1YxZMiQuOOOOzb18lgLUfiCmD9/fsycOTOuvvrqqK2tjcmTJ2/qJW1wF110UbRo0SIef/zxGDFiRIwcOTJmzpwZq1atigsuuGCd9t2/f//4wQ9+ECeccEJcd911ceWVV8bbb78dt9566+fOvP/+++t0zM9TqVSiefPmUVNTs0H2v7HdeOONMW/evLj//vvj0ksvjTPOOCOmT58ee++9d4wYMSKWL1++qZfIGojCF8TkyZOjTZs2MXjw4Dj66KM/NwpLly6Nc845J7p27RrNmjWLTp06xdChQ+PNN9+MGTNmxN577x0RESeccEJ+hPLxZ9ldu3aNYcOG1dnnpz9fXr58eYwaNSr22muv2GabbaJly5bRv3//mD59er2+lzlz5sSrr7661u0effTROOigg6Jt27b52Fe+8pUYMGBAPPDAA/Hee+/V63j1ceCBB0bER/GNiBgzZkxUKpV4/vnn4/vf/360adMm+vXrl9vffvvtsddee0WLFi1i2223jWOOOSZee+21OvudOHFidO/ePVq0aBH77LNPPProo3W2+bzfKcyZMyeGDBkStbW10aJFi9h5553jwgsvzPWNHDkyIiK6deuWr+WCBQs2yBojIl599dWYM2fOGp7Fjzz66KNRW1ubz2lERKNGjWLIkCHxr3/9Kx5++OG17oNNRxS+ICZPnhxHHnlkNG3aNI499tiYO3duzJo1a7Vt3nvvvejfv39cd911MXDgwLj22mtj+PDhMWfOnHj99dejZ8+ecckll0RExI9+9KO47bbb4rbbbov99tuvqrW88847MWnSpNh///3jsssuizFjxsSSJUviO9/5Tr0+lurZs2cMHTp0rdstW7YsWrRoUefxrbbaKpYvXx7PPvtsVetek5dffjkiYrUARUR897vfjf/+978xbty4OOWUUyIiYuzYsTF06NDo0aNHXH311XH22WfHtGnTYr/99lvto5ybbropTj311OjQoUNcfvnl0bdv3zjssMM+84350/7xj3/EvvvuGw899FCccsopce2118bhhx8ef/jDHyIi4sgjj4xjjz02IiJ++ctf5mtZW1u7wdY4dOjQ6Nmz51rXvqbXLeKj3xOxGSts9p588skSEeXPf/5zKaWUVatWlU6dOpWf/OQnq203atSoEhFl6tSpdfaxatWqUkops2bNKhFRfvOb39TZpkuXLuX444+v8/iAAQPKgAED8u8rVqwoy5YtW22b//znP6V9+/blxBNPXO3xiCijR4+u89gn9/d5dt9997LTTjuVFStW5GPLli0rnTt3LhFR7rnnnrXu49OmT59eIqLcfPPNZcmSJWXRokXlj3/8Y+natWupVCpl1qxZpZRSRo8eXSKiHHvssavNL1iwoNTU1JSxY8eu9vgzzzxTGjdunI8vX768tGvXrnz9619f7bmaOHFine9//vz5dV6T/fbbr7Rq1aosXLhwteN8/DqWUsoVV1xRIqLMnz9/g6+xlI/+HdTnLeOss84qjRo1KgsWLFjt8WOOOaZERDnzzDPXug82HWcKXwCTJ0+O9u3bxwEHHBARH30G/b3vfS+mTJkSK1euzO3uvffe6N27dxxxxBF19lGpVNbbempqaqJp06YREbFq1ap4++23Y8WKFdGnT5946qmn1jpfSokZM2asdbvTTz89XnrppTjppJPi+eefj2effTaGDh0ab7zxRkREfPDBBw3+Hk488cSora2N7bffPgYPHhzvv/9+3HrrrdGnT5/Vths+fPhqf586dWqsWrUqhgwZEm+++Wb+6dChQ/To0SM/QnvyySfj3//+dwwfPjyfq4iIYcOGxTbbbLPGtS1ZsiQeeeSROPHEE6Nz586rfa0+r+OGWuOMGTOi1OP/k+vkk0+OmpqaGDJkSMycOTNefvnlGD9+fNx3330RsW6vGxte4029ANZs5cqVMWXKlDjggAPy8+6IiH333TeuuuqqmDZtWgwcODAiPvoI5Kijjtoo67r11lvjqquuijlz5sSHH36Yj3fr1m29HWP48OHx2muvxRVXXJG/AO7Tp0+cd955MXbs2Nh6660bvO9Ro0ZF//79o6amJrbbbrvo2bNnNG5c938On/5+5s6dG6WU6NGjx2fut0mTJhERsXDhwoiIOtt9fAnsmnx8aexuu+1Wv2/mUzbGGtfka1/7Wtxxxx0xfPjw6Nu3b0REdOjQIa655po47bTT1ul1Y8MThc3cQw89FG+88UZMmTIlpkyZUufrkydPziisq8/7KXTlypWrXRlz++23x7Bhw+Lwww+PkSNHRrt27aKmpibGjx+fn82vL2PHjo1zzz03nnvuudhmm21i9913zyuPdtpppwbvd/fdd4+DDjpordt9+rPxVatWRaVSiT/96U+febXQ5vCGtzms8eijj47DDjssnn766Vi5cmXsueeeeXa4Lq8bG54obOYmT54c7dq1i1//+td1vjZ16tS47777YsKECdGiRYvo3r37Wn/5uqaPH9q0afOZ17wvXLhwtZ8c77nnnthxxx1j6tSpq+1v9OjR9fiOqvfpK3/+8pe/RKdOnWKXXXbZIMdbk+7du0cpJbp167bGN7cuXbpExEc/tX/yKpwPP/ww5s+fH7179/7c2Y+f64a+lhtjjfXRtGnTvNot4qPXLSLqFWM2Hb9T2Ix98MEHMXXq1DjkkEPi6KOPrvPnzDPPjHfffTd+//vfR0TEUUcdFU8//XR+dvtJH38W3LJly4iIz3zz7969e/z1r39d7TryBx54oM6VKB//9PnJz5f/9re/xeOPP16v76u+l6R+lrvuuitmzZoVZ599djRqtPH/+R555JFRU1MTF198cZ3P10sp8dZbb0XERx9z1dbWxoQJE1Z7Pm+55Za1/sdmtbW1sd9++8XNN99c53n65DE/77XcUGus7yWpn2Xu3LkxYcKEOOSQQ5wpbO42ya+3qZcpU6aUiCj333//Z3595cqVpba2thx66KGllFLefffdsuuuu5aamppyyimnlAkTJpRx48aVb3zjG2X27NmllI+uOGndunXZeeedy6RJk8qdd95ZXnnllVJKKQ8++GCJiHLAAQeUG264oZx77rmlQ4cOpXv37qtdiXLzzTeXiCiHHXZYufHGG8v5559fWrduXXr16lW6dOmy2hpjHa4+evjhh8u3v/3tctlll5VJkyaVk08+udTU1JRBgwaVDz/8cLVtP75aaPr06Wvc58dXH919991r3O7j/S1ZsqTO18aPH18ionzrW98ql19+ebnhhhvKeeedV3r06FGuuOKK3O7GG28sEVH69u1bfvWrX5VzzjmntG7duuy4445rvfpo9uzZZeutty5t27YtP//5z8vEiRPLBRdcUHr37p3bPPHEEyUiysEHH1x++9vfljvvvLO89957G2SNpdT/6qNSSunZs2cZNWpUmTRpUrnwwgvLtttuW7p06VJef/31es2z6YjCZuzQQw8tzZs3L++///7nbjNs2LDSpEmT8uabb5ZSSnnrrbfKmWeeWTp27FiaNm1aOnXqVI4//vj8eiml/O53vyu77rprady4cZ03o6uuuqp07NixNGvWrPTt27c8+eSTdS5JXbVqVRk3blzp0qVLadasWdljjz3KAw88UI4//vj1GoV58+aVgQMHlu222640a9as7LLLLmX8+PF1LoctpZQRI0aUSqVSXnjhhTXuc31EoZRS7r333tKvX7/SsmXL0rJly7LLLruUM844o7z44ourbXf99deXbt26lWbNmpU+ffqURx55pM7z+VlRKKWUZ599thxxxBGldevWpXnz5mXnnXcuF1100WrbXHrppaVjx46lUaNGdS5PXZ9rLKW6KBxzzDFlhx12KE2bNi3bb799GT58eFm8eHG9Ztm0KqXU4xoz2Mzts88+0aVLFzddg3UkCnzhvfPOO1FbWxuzZ8+u139xC3w+UQAgufoIgCQKACRRACCJAgCp3re5WJ932QRg46vPdUXOFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUuNNvQC+PNq2bduguWuuuabqmeOOO67qmUqlUvVMKaXqmYULF1Y9ExFx2mmnVT3z4IMPNuhYfHk5UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJK7pBJNmjSpeub000+vembEiBFVz0REtG7duuqZW265peqZxx57rOqZhtyN9Zvf/GbVMxERX/3qV6ueachzt3Tp0qpn2HI4UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQHJDPOKnP/1p1TPjxo2rembRokVVz0Q07AZyzz33XIOOVa2HH3646pltt922QcdqyPM3d+7cqmfOP//8qmduuummqmfYPDlTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAckO8Lcxxxx1X9cz48eOrnvnnP/9Z9cygQYOqnonYeDe3a4h58+ZVPdOqVasGHeuee+6peqYhN9/r1atX1TNsOZwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAguSHeFma33Xarembx4sVVzwwePLjqmc35xnYb04EHHtiguYMOOmg9r+SzXXbZZRvlOGyenCkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgCpUkop9dqwUtnQa+ETWrdu3aC5J554ouqZhtwltX///lXPbIm6d+9e9cy0adMadKzOnTs3aK5ajRr5WXFLVZ+3e68+AEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQBS4029AD7b0qVLGzTXkJvbdezYseqZrl27Vj2zYMGCqmcaqnnz5lXPDBo0qOqZk046qeqZ9u3bVz0TEbFy5cqqZ9zcjmr5FwNAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgOSGeFuYadOmVT0zatSoqmdeeOGFqmcefPDBqmcaqnPnzlXP7LHHHlXPLFu2rOqZSy65pOqZiIhzzjmn6pm2bds26Fh8eTlTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAckO8LcwvfvGLqmdatmxZ9czBBx9c9cw+++xT9UxExNKlSxs0V62f/exnVc/cfffdVc/07Nmz6pmIiDZt2lQ9M2vWrAYdiy8vZwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEhuiLeF+d///lf1zMiRIzfKTPv27aueiYhYvHhxg+Y2V717927QXKNG1f8M98wzzzToWHx5OVMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSu6Sy0WxpdzttqIbeLbZSqVQ989hjjzXoWHx5OVMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEByQzxYB1tttVXVM2eddVaDjrVixYqqZ55//vkGHYsvL2cKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIlVJKqdeGlcqGXgt84Wy33XZVzyxevLhBx5ozZ07VM7169WrQsdgy1eft3pkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQBS4029APgiO+644zb1EmC9cqYAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDkhniwDpo1a7bRjjV37tyNdiy+vJwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAyV1SYSOrVCoNmjvppJPW80qgLmcKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIbogHG1kpZVMvAT6XMwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUuNNvQCgfnbYYYeqZ956660NsBK2ZM4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA5C6psA5eeumljXasyZMnVz3Tq1evDbAStmTOFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkCqllFKvDSuVDb0WADag+rzdO1MAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEBqXN8N63nfPAC+wJwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJD+H1X/Kk64ORHXAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHjs7OA3toT2"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}