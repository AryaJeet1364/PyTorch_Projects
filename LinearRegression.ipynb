{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObEqSviZ5jEQ4PiqKp1LuO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryaJeet1364/PyTorch_Projects/blob/main/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual vs Built-in"
      ],
      "metadata": {
        "id": "eviTbX8K9gQ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wbrfByiC6Tlj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To make sure results are the same every time\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "qChprEaB6Xqq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading California housing data\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "ZImhPPsa6bw0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "57zeqWdo6fai"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features so training goes smoother\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "lYovyvWj6iu_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to torch tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "y_train = torch.FloatTensor(y_train).unsqueeze(1)  # to make it (n, 1)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_test = torch.FloatTensor(y_test).unsqueeze(1)"
      ],
      "metadata": {
        "id": "6vIoU3886lc5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual"
      ],
      "metadata": {
        "id": "T08eRCGt9ZX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]  # Number of features\n",
        "W = torch.randn(input_dim, 1, dtype=torch.float32) * 0.01  # Small random weights init\n",
        "b = torch.zeros(1, dtype=torch.float32)  # Bias initialized to zero\n",
        "\n",
        "lr = 0.01  # Learning rate\n",
        "epochs = 1000  # Training iterations\n",
        "n = X_train.shape[0]  # Number of samples\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    y_pred = X_train.mm(W) + b  # Predict output\n",
        "    loss = ((y_pred - y_train) ** 2).mean()  # Compute MSE loss\n",
        "\n",
        "    # Calculating gradients manually\n",
        "    grad_y_pred = 2.0 * (y_pred - y_train) / n\n",
        "    grad_W = X_train.t().mm(grad_y_pred)  # Gradient for weights\n",
        "    grad_b = grad_y_pred.sum()  # Gradient for bias\n",
        "\n",
        "    # Update parameters using gradient descent\n",
        "    W -= lr * grad_W\n",
        "    b -= lr * grad_b\n",
        "\n",
        "    # Printing loss every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training MSE: {loss.item():.4f}\")\n",
        "\n",
        "final_train_loss = loss.item()  # Final training loss\n",
        "\n",
        "# Evaluate test loss without tracking gradients\n",
        "with torch.no_grad():\n",
        "    y_test_pred = X_test.mm(W) + b\n",
        "    test_loss = ((y_test_pred - y_test) ** 2).mean().item()\n",
        "\n",
        "print(\"\\n== Manual Linear Regression ==\")\n",
        "print(f\"Final Training MSE: {final_train_loss:.4f}\")\n",
        "print(f\"Test MSE: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynIFzo7j6rTo",
        "outputId": "e09d229e-37e7-40a2-83fb-3cc97f2ff871"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000, Training MSE: 5.6304\n",
            "Epoch 101/1000, Training MSE: 0.7116\n",
            "Epoch 201/1000, Training MSE: 0.5962\n",
            "Epoch 301/1000, Training MSE: 0.5739\n",
            "Epoch 401/1000, Training MSE: 0.5589\n",
            "Epoch 501/1000, Training MSE: 0.5481\n",
            "Epoch 601/1000, Training MSE: 0.5401\n",
            "Epoch 701/1000, Training MSE: 0.5343\n",
            "Epoch 801/1000, Training MSE: 0.5301\n",
            "Epoch 901/1000, Training MSE: 0.5270\n",
            "\n",
            "== Manual Linear Regression ==\n",
            "Final Training MSE: 0.5247\n",
            "Test MSE: 0.5547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using NN module"
      ],
      "metadata": {
        "id": "LnWOL1Yz9bKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- PyTorch nn.Linear Model --------\n",
        "class TorchLinear(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = TorchLinear(X_train.shape[1])\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Train nn.Linear model\n",
        "for i in range(1000):\n",
        "    preds = model(X_train)\n",
        "    loss = loss_fn(preds, y_train)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if(i%100 == 0):\n",
        "        print(f\"Epoch {i+1}/{1000}, Training MSE: {loss.item():.4f}\")\n",
        "\n",
        "final_train_loss_nn = loss.item()\n",
        "\n",
        "# Test loss\n",
        "with torch.no_grad():\n",
        "    preds_test_nn = model(X_test)\n",
        "    test_loss_nn = loss_fn(preds_test_nn, y_test).item()\n",
        "\n",
        "print(\"== PyTorch nn.Linear ==\")\n",
        "print(f\"Final Training MSE: {final_train_loss_nn:.4f}\")\n",
        "print(f\"Test MSE: {test_loss_nn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D-tsvWN6weI",
        "outputId": "1795d39c-ee89-45cb-82d3-bf26eea22f07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000, Training MSE: 6.6704\n",
            "Epoch 101/1000, Training MSE: 0.7193\n",
            "Epoch 201/1000, Training MSE: 0.5898\n",
            "Epoch 301/1000, Training MSE: 0.5699\n",
            "Epoch 401/1000, Training MSE: 0.5568\n",
            "Epoch 501/1000, Training MSE: 0.5472\n",
            "Epoch 601/1000, Training MSE: 0.5400\n",
            "Epoch 701/1000, Training MSE: 0.5347\n",
            "Epoch 801/1000, Training MSE: 0.5307\n",
            "Epoch 901/1000, Training MSE: 0.5278\n",
            "== PyTorch nn.Linear ==\n",
            "Final Training MSE: 0.5255\n",
            "Test MSE: 0.5588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kjxwCUQC60Gp"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}